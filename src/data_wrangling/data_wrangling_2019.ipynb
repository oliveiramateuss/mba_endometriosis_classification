{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc # Garbage collector\n",
    "\n",
    "from utils.feature_scope import get_feature_scope\n",
    "from utils.transformation_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNS 2019 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"..\\..\\data\\staged\\PNS_2019.parquet\")\n",
    "\n",
    "print(f\"Count of df: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Females\n",
    "only_females = df['C006'] == \"2\"\n",
    "\n",
    "# Apply filters\n",
    "df_filtered = df[only_females]\n",
    "df_filtered = df_filtered[df_filtered['C008'].str.strip() != \".\"]\n",
    "df_filtered = df_filtered[df_filtered['C008'].str.strip() != \"\" ]\n",
    "\n",
    "print(f\"Count of df_filtered: {len(df_filtered)}\")\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = []\n",
    "\n",
    "for modulo in get_feature_scope():\n",
    "    for column in modulo:\n",
    "        for key in column.keys():\n",
    "            if key in df_filtered.columns:\n",
    "                columns_to_select.append(key)    \n",
    "\n",
    "df_filtered = df_filtered[columns_to_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any column that has only spaces and \".\" by \"<None>\"\n",
    "df_cleaned = df_filtered.apply(lambda x: x.map(lambda y: \"<None>\" if isinstance(y, str) and (y.strip() == '.' or y.strip() == '') else y))\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "DEFAULT_NUMBER = 0\n",
    "\n",
    "# Read feature type inference from JSON file\n",
    "with open(\"../../data/schema/feature_type_inference.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    feature_types_infered = json.load(f)\n",
    "\n",
    "df_transformed = df_cleaned.copy()\n",
    "\n",
    "# Dynamically call the transformation function based on the column name\n",
    "for column in df_transformed.columns:\n",
    "\n",
    "    transform_function_name = f\"transform_{column}\"\n",
    "\n",
    "    if transform_function_name in globals():\n",
    "        transform_function = globals()[transform_function_name]\n",
    "        df_transformed = transform_function(df_transformed)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Apply type transformation based on the feature type inference\n",
    "        if column in feature_types_infered:\n",
    "            column_type = feature_types_infered[column][\"type\"]\n",
    "            \n",
    "            if column_type == \"numeric\":\n",
    "                df_transformed[column] = df_transformed[column].replace(\"<None>\", DEFAULT_NUMBER)\n",
    "                df_transformed = df_transformed.astype({column: int})\n",
    "            elif column_type == \"float\":\n",
    "                df_transformed[column] = df_transformed[column].replace(\"<None>\", DEFAULT_NUMBER)\n",
    "                df_transformed = df_transformed.astype({column: float})\n",
    "            elif column_type == \"category\":\n",
    "                df_transformed = df_transformed.astype({column: 'category'})\n",
    "            elif column_type == \"boolean\":\n",
    "                df_transformed[column] = df_transformed[column].apply(lambda x: 1 if x == \"1\" else 0)\n",
    "                df_transformed = df_transformed.astype({column: int})\n",
    "\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to stage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.to_parquet(\"..\\..\\data\\staged\\PNS_2019_transformed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the dfs that are no longer needed\n",
    "del df\n",
    "del df_filtered\n",
    "del df_cleaned\n",
    "del df_transformed\n",
    "\n",
    "# Run garbage collection to free up memory\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
