{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\mateu\\workspace\\tcc\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PNS 2013'], ['dicion√°rio pns'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both spreadsheets\n",
    "xls_2013 = pd.ExcelFile(\"./schema/data_mapping_2013.xls\")\n",
    "xls_2019 = pd.ExcelFile(\"./schema/data_mapping_2019.xls\")\n",
    "\n",
    "# Check the sheet names to determine how to proceed\n",
    "xls_2013.sheet_names, xls_2019.sheet_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming data is in the first sheet, update if otherwise\n",
    "df_2013 = xls_2013.parse(xls_2013.sheet_names[0])\n",
    "df_2019 = xls_2019.parse(xls_2019.sheet_names[0])\n",
    "\n",
    "# Select only relevant columns and rename them to a standard naming convention\n",
    "columns_mapping = {'A': 'initial_position', 'B': 'length', 'C': 'key', 'D': 'sub_key', 'E': 'description'}\n",
    "df_2013 = df_2013.iloc[:, :5].rename(columns=dict(zip(df_2013.columns[:5], columns_mapping.values())))\n",
    "df_2019 = df_2019.iloc[:, :5].rename(columns=dict(zip(df_2019.columns[:5], columns_mapping.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_14376\\4116112025.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_2013 = df_2013.fillna(\"\")\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_14376\\4116112025.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_2019 = df_2019.fillna(\"\")\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all columns and replace \"NaN\" with \"\"\n",
    "for col in df_2013.columns:\n",
    "    df_2013[col] = df_2013[col].replace(\"NaN\", \"\")\n",
    "    df_2019[col] = df_2019[col].replace(\"NaN\", \"\")\n",
    "\n",
    "df_2013 = df_2013.fillna(\"\")\n",
    "df_2019 = df_2019.fillna(\"\")\n",
    "\n",
    "# Remove rows where initial_position is not a number\n",
    "df_2013 = df_2013[df_2013['initial_position'].apply(lambda x: str(x).isdigit())]\n",
    "df_2019 = df_2019[df_2019['initial_position'].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "# Remove rows where initial_position is \"NaN\"\n",
    "df_2013 = df_2013[df_2013['initial_position'] != \"\"]\n",
    "df_2019 = df_2019[df_2019['initial_position'] != \"\"]\n",
    "\n",
    "# Convert length to int\n",
    "df_2013['length'] = df_2013['length'].astype(int)\n",
    "df_2019['length'] = df_2019['length'].astype(int)\n",
    "\n",
    "# Convert DataFrames to JSON\n",
    "json_2013 = df_2013.to_dict(orient='records')\n",
    "json_2019 = df_2019.to_dict(orient='records')\n",
    "\n",
    "# Save JSON files\n",
    "with open('data_mapping_2013.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_2013, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('data_mapping_2019.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_2019, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
